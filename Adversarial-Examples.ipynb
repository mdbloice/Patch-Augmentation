{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness to Adversarial Examples\n",
    "\n",
    "In this notebook we test whether *patch augmentation* creates models that are more robust to adversarial examples.\n",
    "\n",
    "To do this, we used the *CleverHans* library and created adversarial examples using the Fast Gradient Sign Method attack.\n",
    "\n",
    "Notes:\n",
    "- More methods will follow and will be added to this notebook.\n",
    "- Portions of this code from COMPSCI 109B lab material, Harvard University. See <https://harvard-iacs.github.io/2019-CS109B/lecture/lab21/AdversarialNN/> for a tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Gradient Sign Method\n",
    "\n",
    "The Fast Gradient Sign Method (FSGM)is a white-box attack, meaning you need access to the model in order for adversarial examples to be crafted. In FGSM the trained network's gradients are used to generate adversarial examples. For any given input image $x$, FGSM uses the gradients of the loss w.r.t. to $x$ to create a new image, $\\tilde{x}$, that maximises the loss: \n",
    "\n",
    "$$\n",
    "\\tilde{x} = x + \\epsilon \\cdot \\text{sign}( \\nabla_x J(\\theta, x, y) )\n",
    "$$\n",
    "\n",
    "See <https://www.tensorflow.org/tutorials/generative/adversarial_fgsm> for further details and a good tutorial on how to create such adversarial examples using FGSM.\n",
    "\n",
    "However, in this notebook we will be using the CleverHans Python package rather than implementing FGSM. CleverHans allows us to interface with Keras produced models.\n",
    "\n",
    "First we begin with imports. This model has been trained on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "\n",
    "session = tf.Session()\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Keras to fetch our CIFAR-10 image data, and preprocess it in the same way that was done for when the models were trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the non one-hot-encoding labels later, so store these as y_train_nc and y_test_nc\n",
    "(x_train, y_train_nc), (x_test, y_test_nc) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train_nc, 10)\n",
    "y_test = keras.utils.to_categorical(y_test_nc, 10)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_train_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the best performing patch augmentation model and the best performing model that used no augmentation (`network` is the model trained without any augmentation, `patch_network` was trained using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./cifar10_no_aug_ResNet20v2_model.114.h5')\n",
    "patch_model = load_model('./cifar10_p05_a05_ResNet20v2_model.105.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both networks were of the type ResNet20v2, the patch augmentation parameters were `probability=0.5` and `patch_area=0.5`.\n",
    "\n",
    "Here we load in the network using the Keras model wrapper, and also set the $\\epsilon$ value (`fgsm_rate`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = KerasModelWrapper(patch_model)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "fgsm = FastGradientMethod(wrap, sess=session)\n",
    "\n",
    "# Here we set epsilon\n",
    "fgsm_rate = 0.001\n",
    "\n",
    "fgsm_params = {'eps': fgsm_rate,'clip_min': -1.,'clip_max': 1.}\n",
    "adv_x = fgsm.generate(x, **fgsm_params)\n",
    "adv_x = tf.stop_gradient(adv_x)\n",
    "adv_prob = patch_model(adv_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the number of adversarial samples we wish to create using `test_cases`. We compare the network's performance on the adversarial examples on both networks to see how well each network can handle adversarial attacks. \n",
    "\n",
    "In our experiments, using all test samples would cause 'Resource exhausted' errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_cases = 1000\n",
    "fetches = [adv_prob]\n",
    "fetches.append(adv_x)\n",
    "outputs = session.run(fetches=fetches, feed_dict={x:x_test[:test_cases]}) \n",
    "adv_prob = outputs[0]\n",
    "adv_examples = outputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many of the adversarial examples were correctly predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/1000 correctly predicted.\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(test_cases):\n",
    "    if np.argmax(adv_prob[i]) == np.argmax(y_test[i]):\n",
    "        correct += 1\n",
    "print(\"%s/%s correctly predicted.\" % (correct, test_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the non-augmented network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/1000 correctly predicted.\n"
     ]
    }
   ],
   "source": [
    "wrap = KerasModelWrapper(model)\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "fgsm = FastGradientMethod(wrap, sess=session)\n",
    "fgsm_params = {'eps': fgsm_rate,'clip_min': -1.,'clip_max': 1.}\n",
    "adv_x = fgsm.generate(x, **fgsm_params)\n",
    "adv_x = tf.stop_gradient(adv_x)\n",
    "adv_prob = model(adv_x)\n",
    "fetches = [adv_prob]\n",
    "fetches.append(adv_x)\n",
    "outputs = session.run(fetches=fetches, feed_dict={x:x_test[:test_cases]}) \n",
    "adv_prob = outputs[0]\n",
    "adv_examples = outputs[1]\n",
    "correct = 0\n",
    "for i in range(test_cases):\n",
    "    if np.argmax(adv_prob[i]) == np.argmax(y_test[i]):\n",
    "        correct += 1\n",
    "print(\"%s/%s correctly predicted.\" % (correct, test_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the network trained with patch augmentation is more resilient to this type of adversarial attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we adjust $\\epsilon$ we can create adversarial images that are more difficult for the network to classify. The higher the value for $\\epsilon$ the more noise they contain, until they become perceptible even to the human eye.\n",
    "\n",
    "When we adjust $\\epsilon$ to a higher value, let's say $0.03$ we see that both networks perform much worse, but the network trained using patch augmentation still performs better of the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch augmentation: 201/1000 correctly predicted.\n",
      "No augmentation 138/1000 correctly predicted.\n"
     ]
    }
   ],
   "source": [
    "fgsm_rate = 0.03\n",
    "\n",
    "# Patch Augmentation Network:\n",
    "wrap = KerasModelWrapper(patch_model)\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "fgsm = FastGradientMethod(wrap, sess=session)\n",
    "fgsm_params = {'eps': fgsm_rate,'clip_min': -1.,'clip_max': 1.}\n",
    "adv_x = fgsm.generate(x, **fgsm_params)\n",
    "adv_x = tf.stop_gradient(adv_x)\n",
    "adv_prob = patch_model(adv_x)\n",
    "fetches = [adv_prob]\n",
    "fetches.append(adv_x)\n",
    "outputs = session.run(fetches=fetches, feed_dict={x:x_test[:test_cases]}) \n",
    "adv_prob = outputs[0]\n",
    "adv_examples = outputs[1]\n",
    "correct = 0\n",
    "for i in range(test_cases):\n",
    "    if np.argmax(adv_prob[i]) == np.argmax(y_test[i]):\n",
    "        correct += 1\n",
    "print(\"Patch augmentation: %s/%s correctly predicted.\" % (correct, test_cases))\n",
    "\n",
    "# No Augmentation Network:\n",
    "wrap = KerasModelWrapper(model)\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "fgsm = FastGradientMethod(wrap, sess=session)\n",
    "fgsm_params = {'eps': fgsm_rate,'clip_min': -1.,'clip_max': 1.}\n",
    "adv_x = fgsm.generate(x, **fgsm_params)\n",
    "adv_x = tf.stop_gradient(adv_x)\n",
    "adv_prob = model(adv_x)\n",
    "fetches = [adv_prob]\n",
    "fetches.append(adv_x)\n",
    "outputs = session.run(fetches=fetches, feed_dict={x:x_test[:test_cases]}) \n",
    "adv_prob = outputs[0]\n",
    "adv_examples = outputs[1]\n",
    "correct = 0\n",
    "for i in range(test_cases):\n",
    "    if np.argmax(adv_prob[i]) == np.argmax(y_test[i]):\n",
    "        correct += 1\n",
    "print(\"No augmentation %s/%s correctly predicted.\" % (correct, test_cases))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
